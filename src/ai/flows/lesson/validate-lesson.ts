'use server';
/**
 * @fileOverview This file defines the Genkit flow for validating a synthesized lesson.
 *
 * The flow takes a lesson draft as input and uses an AI model to check for factual accuracy,
 * plagiarism, and logical errors. It returns a validation result object.
 *
 * @exports validateLesson - The main function to validate a lesson draft.
 * @exports ValidateLessonInput - The input type for the validateLesson function.
 * @exports ValidateLessonOutput - The output type for the validateLesson function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';
import {SynthesizeLessonOutputSchema} from './synthesize-lesson';

export const ValidateLessonInputSchema = z.object({
  lessonDraft: SynthesizeLessonOutputSchema.describe('The lesson object to be validated.'),
});
export type ValidateLessonInput = z.infer<typeof ValidateLessonInputSchema>;

export const ValidateLessonOutputSchema = z.object({
  valid: z.boolean().describe('A boolean indicating if the lesson is considered valid and ready for use.'),
  confidence_score: z.number().min(0).max(1).describe('A score from 0.0 to 1.0 representing the confidence in the lesson\'s quality.'),
  issues: z.array(
    z.object({
      type: z.string().describe('The type of issue found (e.g., "Factual Error", "Plagiarism Concern", "Clarity").'),
      detail: z.string().describe('A detailed description of the specific issue.'),
    })
  ).describe('A list of issues found in the lesson draft. Empty if the lesson is valid.'),
});
export type ValidateLessonOutput = z.infer<typeof ValidateLessonOutputSchema>;

export async function validateLesson(input: ValidateLessonInput): Promise<ValidateLessonOutput> {
  return validateLessonFlow(input);
}

const validatePrompt = ai.definePrompt({
  name: 'validateLessonPrompt',
  input: {schema: ValidateLessonInputSchema},
  output: {schema: ValidateLessonOutputSchema},
  prompt: `You are an expert quality assurance editor for educational content. Your task is to review and validate a lesson draft generated by another AI.

Analyze the provided lesson draft:
'''json
{{{jsonStringify lessonDraft}}}
'''

**Validation Criteria:**

1.  **Factual Accuracy:** Is the information correct and up-to-date? Are there any misleading statements or technical errors?
2.  **Clarity and Coherence:** Is the lesson well-structured and easy to understand for the target audience? Does it flow logically? Is the content at least 600 words?
3.  **Originality:** Does the content appear to be synthesized and original, or is it just copied from a few sources? (You don't have the original sources, but you can judge based on the writing style).
4.  **Completeness:** Does the lesson fulfill the goals outlined in its summary and introduction?

**Your Task:**

1.  Provide a 'confidence_score' from 0.0 (very low quality) to 1.0 (perfectly written).
2.  Set 'valid' to \`true\` only if the 'confidence_score' is 0.7 or higher. Otherwise, set it to \`false\`.
3.  If 'valid' is \`false\`, you MUST populate the 'issues' array with specific, actionable problems that need to be fixed. For each issue, provide a 'type' and a 'detail'.

Your final output must be a single, valid JSON object that strictly conforms to the output schema.
`,
});

const validateLessonFlow = ai.defineFlow(
  {
    name: 'validateLessonFlow',
    inputSchema: ValidateLessonInputSchema,
    outputSchema: ValidateLessonOutputSchema,
  },
  async input => {
    const {output} = await validatePrompt(input);
    if (!output) {
      throw new Error('Failed to get a valid response from the AI model.');
    }

    // Enforce the business rule: if score < 0.7, valid must be false.
    if (output.confidence_score < 0.7 && output.valid) {
      output.valid = false;
      if (output.issues.length === 0) {
        output.issues.push({
          type: 'Low Confidence',
          detail: `The overall confidence score of ${output.confidence_score} is below the required threshold of 0.7, but no specific issues were itemized. Manual review is required.`,
        });
      }
    }
    
    return output;
  }
);
